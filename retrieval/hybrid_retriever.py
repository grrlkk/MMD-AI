import json
import argparse
import time
import sys
import os

# --- ì„¤ì •ê°’ ---
CANDIDATE_K = 100
ALPHA = 0.3
# -------------

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from . import dense
from . import sparse
from db.opensearch import OpenSearchDB


def normalize_scores(scores_dict: dict) -> dict:
    """Min-Max ì •ê·œí™”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì ìˆ˜ë¥¼ 0ê³¼ 1 ì‚¬ì´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not scores_dict:
        return {}
    
    scores = list(scores_dict.values())
    min_score, max_score = min(scores), max(scores)

    if max_score == min_score:
        return {doc_id: 1.0 for doc_id in scores_dict} # ëª¨ë“  ì ìˆ˜ê°€ ê°™ìœ¼ë©´ 1ì ìœ¼ë¡œ í†µì¼
        
    normalized = {
        doc_id: (score - min_score) / (max_score - min_score)
        for doc_id, score in scores_dict.items()
    }
    return normalized


def fetch_documents_by_ids(opensearch_client: OpenSearchDB, doc_ids: list[str]) -> dict[str, dict]:
    """ì£¼ì–´ì§„ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•´ OpenSearchì—ì„œ ì „ì²´ ë¬¸ì„œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    if not doc_ids:
        return {}
    
    query = {"query": {"terms": {"_id": doc_ids}}, "size": len(doc_ids)}
    response = opensearch_client.search(query)
    return {hit['_id']: hit['_source'] for hit in response.get("hits", {}).get("hits", [])}


def print_reranked_results(final_results: list[dict], documents_map: dict):
    """ìµœì¢… ì¬ì •ë ¬ëœ ê²°ê³¼ë¥¼ bm25_retriever.pyì™€ ë™ì¼í•œ ìƒì„¸ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if not final_results:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\n\n--- ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ (ì¬ì •ë ¬ ë°©ì‹) ---")
    for i, result in enumerate(final_results, 1):
        doc_id = result['id']
        document = documents_map.get(doc_id)
        
        if not document:
            continue

        print(f"\n[ ìµœì¢… ìˆœìœ„ {i} ] (ID: {doc_id})")
        print(f" ìµœì¢… Score: {result['final_score']:.4f}")
        print(f"  - Dense  ì ìˆ˜: {result['dense_score']:.4f} (ì •ê·œí™”: {result['norm_dense_score']:.4f})")
        print(f"  - Sparse ì ìˆ˜: {result['sparse_score']:.2f} (ì •ê·œí™”: {result['norm_sparse_score']:.4f})")
        print("-" * 100)
        
        print(f"ì œëª©: {document.get('title', 'ì •ë³´ ì—†ìŒ')}")
        print(f"íšŒì‚¬ëª…: {document.get('company_name', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ì§ë¬´: {document.get('title', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ìƒì„¸ ë‚´ìš©: {document.get('position_detail', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ì£¼ìš” ì—…ë¬´: {document.get('main_tasks', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ìê²©ìš”ê±´: {document.get('qualifications', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ìš°ëŒ€ì‚¬í•­: {document.get('preferred_qualifications', 'ì •ë³´ ì—†ìŒ')}")
        print(f"í˜œíƒ ë° ë³µì§€: {document.get('benefits', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ì±„ìš© ì „í˜•: {document.get('hiring_process', 'ì •ë³´ ì—†ìŒ')}")
        
        tech_stack_list = document.get('tech_stack', [])
        if isinstance(tech_stack_list, list):
             print(f"ê¸°ìˆ ìŠ¤íƒ: {', '.join(tech_stack_list) if tech_stack_list else 'ì •ë³´ ì—†ìŒ'}")
        else:
             print(f"ê¸°ìˆ ìŠ¤íƒ: {tech_stack_list or 'ì •ë³´ ì—†ìŒ'}")

        print(f"ì§ë¬´ ì¹´í…Œê³ ë¦¬: {document.get('job_category', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ì§€ì—­: {document.get('location', 'ì •ë³´ ì—†ìŒ')}")
        print("-" * 100)

# --- [ìˆ˜ì •ëœ main í•¨ìˆ˜] ---
def main():
    parser = argparse.ArgumentParser(description="Advanced Hybrid Retriever with Re-ranking.")
    parser.add_argument("user_json", help="Path to the user JSON file.")
    parser.add_argument("--top_k", type=int, default=10, help="Final number of results to display.")
    args = parser.parse_args()

    with open(args.user_json, 'r', encoding='utf-8') as f:
        user_data = json.load(f)

    overall_start_time = time.time()

    # --- 1ë‹¨ê³„: í›„ë³´êµ° ìƒì„± ---
    stage1_start_time = time.time()
    print(f"ğŸ” 1ë‹¨ê³„: ê° ë¦¬íŠ¸ë¦¬ë²„ì—ì„œ Top {CANDIDATE_K} í›„ë³´êµ°ì„ ê°€ì ¸ì˜µë‹ˆë‹¤...")
    dense_results_raw = dense.search(user_data, top_k=CANDIDATE_K)
    sparse_results_raw = sparse.search(user_data, top_k=CANDIDATE_K)
    stage1_duration = time.time() - stage1_start_time
    print(f"   (1ë‹¨ê³„ ì†Œìš” ì‹œê°„: {stage1_duration:.3f}ì´ˆ)")

    dense_results = {str(doc_id).replace("doc-", ""): score for doc_id, score in dense_results_raw}
    sparse_results = {str(doc_id).replace("doc-", ""): score for doc_id, score in sparse_results_raw}

    # --- 2ë‹¨ê³„: ì¬ì •ë ¬ ---
    stage2_start_time = time.time()
    print("\nğŸ”„ 2ë‹¨ê³„: ì ìˆ˜ ì •ê·œí™” ë° ê°€ì¤‘í•©ìœ¼ë¡œ ì¬ì •ë ¬ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
    
    all_candidate_ids = set(dense_results.keys()) | set(sparse_results.keys())
    print(f"-> ì´ {len(all_candidate_ids)}ê°œì˜ ê³ ìœ  í›„ë³´êµ° ìƒì„± ì™„ë£Œ.")

    overlap_count = len(set(dense_results.keys()) & set(sparse_results.keys()))
    print(f"-> ê·¸ ì¤‘ {overlap_count}ê°œê°€ Denseì™€ Sparse ëª©ë¡ì— ê³µí†µìœ¼ë¡œ ì¡´ì¬í•©ë‹ˆë‹¤.")
    
    norm_dense_scores = dense_results
    norm_sparse_scores = normalize_scores(sparse_results)

    fused_results = []
    for doc_id in all_candidate_ids:
        d_score = dense_results.get(doc_id, 0.0)
        s_score = sparse_results.get(doc_id, 0.0)
        norm_d_score = norm_dense_scores.get(doc_id, 0.0)
        norm_s_score = norm_sparse_scores.get(doc_id, 0.0)
        final_score = (ALPHA * norm_d_score) + ((1 - ALPHA) * norm_s_score)
        
        fused_results.append({
            "id": doc_id, "final_score": final_score, "dense_score": d_score,
            "sparse_score": s_score, "norm_dense_score": norm_d_score,
            "norm_sparse_score": norm_s_score
        })

    fused_results.sort(key=lambda x: x["final_score"], reverse=True)
    stage2_duration = time.time() - stage2_start_time
    print(f"   (2ë‹¨ê³„ ì†Œìš” ì‹œê°„: {stage2_duration:.3f}ì´ˆ)")
    
    # --- 3ë‹¨ê³„: ê²°ê³¼ ì¡°íšŒ ë° ì¶œë ¥ ---
    stage3_start_time = time.time()
    print("\nâœ… 3ë‹¨ê³„: ìµœì¢… ìˆœìœ„ì— ë”°ë¼ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤...")
    
    final_top_k_results = fused_results[:args.top_k]
    final_doc_ids = [res['id'] for res in final_top_k_results]

    opensearch_client = OpenSearchDB()
    documents_map = fetch_documents_by_ids(opensearch_client, final_doc_ids)

    print_reranked_results(final_top_k_results, documents_map)
    stage3_duration = time.time() - stage3_start_time
    print(f"   (3ë‹¨ê³„ ì†Œìš” ì‹œê°„: {stage3_duration:.3f}ì´ˆ)")

    total_time = time.time() - overall_start_time
    print(f"\nâ± ì´ ì†Œìš” ì‹œê°„: {total_time:.3f} ì´ˆ")

if __name__ == "__main__":
    main()