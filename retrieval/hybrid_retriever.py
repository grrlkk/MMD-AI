import os
import sys
import torch
import time # time ëª¨ë“ˆ ì„í¬íŠ¸

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from db.opensearch import OpenSearchDB
from langchain_huggingface import HuggingFaceEmbeddings


DEFAULT_TOP_K = 5

# ì „ì—­ ì„ë² ë”© ëª¨ë¸ (í•œ ë²ˆë§Œ ì´ˆê¸°í™”)
_embedding_model = None

def get_embedding_model():
    """ì„ë² ë”© ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤ (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    global _embedding_model
    if _embedding_model is None:
        print("Initializing embedding model for hybrid search...")
        model_load_start = time.time() # ì‹œê°„ ì¸¡ì • ì‹œì‘
        _embedding_model = HuggingFaceEmbeddings(
            model_name="intfloat/multilingual-e5-large",
            model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        model_load_duration = time.time() - model_load_start # ì‹œê°„ ì¸¡ì • ì¢…ë£Œ
        print(f"âœ… Embedding model initialized on {'cuda' if torch.cuda.is_available() else 'cpu'} (ì†Œìš” ì‹œê°„: {model_load_duration:.2f}ì´ˆ)")
    return _embedding_model

def build_hybrid_query(user_input: dict, top_k: int = DEFAULT_TOP_K, exclude_ids: list = None) -> dict:
    """
    BM25ì™€ KNNì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if exclude_ids is None:
        exclude_ids = []

    major = user_input.get("candidate_major", "")
    interest = user_input.get("candidate_interest", "")
    career = user_input.get("candidate_career", "")
    tech_stack = " ".join(user_input.get("candidate_tech_stack", []))
    location = user_input.get("candidate_location", "")
    
    # ê²€ìƒ‰ í…ìŠ¤íŠ¸ êµ¬ì„± (ì˜ë¯¸ì  ê²€ìƒ‰ìš©)
    search_text = f"{interest} {tech_stack} {major} {career}".strip()
    
    # ì„ë² ë”© ëª¨ë¸ë¡œ ì¿¼ë¦¬ ë²¡í„° ìƒì„±
    embedding_model = get_embedding_model()
    query_vector = embedding_model.embed_query(f"query: {search_text}") # e5 ëª¨ë¸ì€ "query: " ì ‘ë‘ì‚¬ ì‚¬ìš©
    
    # ì œì™¸í•  IDê°€ ìˆì„ ê²½ìš° must_not ì ˆ êµ¬ì„±
    must_not_clauses = []
    if exclude_ids:
        must_not_clauses.append({"ids": {"values": exclude_ids}})

    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
    search_query = {
        "query": {
            "bool": {
                "should": [
                    # BM25 ê¸°ë°˜ ê²€ìƒ‰ (ê¸°ì¡´ ë¡œì§)
                    {"multi_match": {"query": interest, "fields": ["job_name^3", "title^2", "position_detail"], "boost": 3.0}},
                    {"multi_match": {"query": tech_stack, "fields": ["tech_stack^2", "preferred_qualifications", "qualifications"], "boost": 2.5}},
                    {"multi_match": {"query": f"{major} {career}", "fields": ["qualifications", "preferred_qualifications"], "boost": 1.5}},
                    {"match": {"location": {"query": location.split(',')[0].strip(), "boost": 3}}} if location else None,
                    
                    # KNN ì˜ë¯¸ì  ê²€ìƒ‰ ì¶”ê°€
                    {"knn": {"embedding": {"vector": query_vector, "k": top_k * 2, "boost": 2.0}}}
                ],
                "must_not": must_not_clauses,
                "minimum_should_match": 1
            }
        },
        "size": top_k,
        "_source": {"excludes": ["embedding"]}
    }
    
    search_query["query"]["bool"]["should"] = [q for q in search_query["query"]["bool"]["should"] if q is not None]

    return search_query

def hybrid_search(user_profile: dict, top_k: int = 5, exclude_ids: list = None) -> tuple[list[float], list[str], list[dict]]:
    """
    BM25 + ì˜ë¯¸ì  ê²€ìƒ‰ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
    """
    opensearch = OpenSearchDB()
    total_start_time = time.time()

    try:
        # í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ìƒì„± (ë‚´ë¶€ì—ì„œ ì„ë² ë”© ìˆ˜í–‰)
        query_gen_start = time.time()
        search_query = build_hybrid_query(user_profile, top_k, exclude_ids)
        query_gen_duration = time.time() - query_gen_start
        
        print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰: BM25 + KNN")
        print(f"ğŸ“ ê²€ìƒ‰ì–´: {user_profile.get('candidate_interest', '')} {' '.join(user_profile.get('candidate_tech_stack', []))}")
        
        # ê²€ìƒ‰ ì‹¤í–‰
        search_start = time.time()
        response = opensearch.search(search_query, size=top_k)
        search_duration = time.time() - search_start
        
    except Exception as e:
        print(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return [], [], []
    
    scores, documents, doc_ids = [], [], []
    hits = response.get("hits", {}).get("hits", [])
    print(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(hits)}ê°œ ê²°ê³¼ ë°˜í™˜")
    
    for hit in hits:
        scores.append(hit.get("_score", 0.0))
        documents.append(hit.get("_source", {}))
        doc_ids.append(hit.get("_id", ""))
    
    total_duration = time.time() - total_start_time
    # --- [ì‹œê°„ ì¸¡ì • ì¶œë ¥ ì¶”ê°€] ---
    print("-" * 50)
    print(f"â±ï¸ ì¿¼ë¦¬ ë²¡í„° ìƒì„± ì‹œê°„: {query_gen_duration:.2f}ì´ˆ")
    print(f"â±ï¸ OpenSearch ê²€ìƒ‰ ì‹œê°„: {search_duration:.2f}ì´ˆ")
    print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„ (ëª¨ë¸ ë¡œë”© ì œì™¸): {total_duration:.2f}ì´ˆ")
    print("-" * 50)
    # --------------------------

    return scores, doc_ids, documents


if __name__ == "__main__":
    base_user_info = {
        "user_id": 10,
        "candidate_major": "ê²½ì˜í•™",
        "candidate_interest": "ì„œë¹„ìŠ¤ ê¸°íšì",
        "candidate_career": "5ë…„",
        "candidate_tech_stack": [
            "UX/UI ì„¤ê³„", "ë°ì´í„° ë¶„ì„", "A/B í…ŒìŠ¤íŠ¸", "í”„ë¡œì íŠ¸ ê´€ë¦¬"
        ],
        "candidate_location": "ì¶©ë‚¨, ì¶©ë¶, ëŒ€ì „",
        "candidate_question": "ì•ˆë…•í•˜ì„¸ìš”, ì„œë¹„ìŠ¤ ê¸°íšì ì§ë¬´ì— ì í•©í•œ í¬ì§€ì…˜ì´ ìˆì„ê¹Œìš”?"
    }
    
    print("\n=== í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ===")
    scores, doc_ids, documents = hybrid_search(base_user_info, top_k=5)
    
    if not scores:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for i, (score, doc_id, document) in enumerate(zip(scores, doc_ids, documents), 1):
            print(f"\n[í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê²°ê³¼ {i}] ì ìˆ˜: {score:.2f}, ë¬¸ì„œ ID: {doc_id}")
            print(f"ì œëª©: {document.get('title', 'ì •ë³´ ì—†ìŒ')}")
            print(f"íšŒì‚¬ëª…: {document.get('company_name', 'ì •ë³´ ì—†ìŒ')}")
            print(f"ì§€ì—­: {document.get('location', 'ì •ë³´ ì—†ìŒ')}")
            print(f"ì§ë¬´: {document.get('title', 'ì •ë³´ ì—†ìŒ')}")
            print(f"ê¸°ìˆ  ìŠ¤íƒ â€¢ íˆ´: {document.get('tech_stack', 'ì •ë³´ ì—†ìŒ')}")
            print(f"ìê²©ìš”ê±´: {document.get('qualifications', 'ì •ë³´ ì—†ìŒ')}")
            print(f"ì£¼ìš” ì—…ë¬´: {document.get('main_tasks', 'ì •ë³´ ì—†ìŒ')}")
            print("-" * 50)
